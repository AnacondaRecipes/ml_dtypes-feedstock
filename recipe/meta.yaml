{% set name = "ml_dtypes" %}
{% set version = "0.5.3" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
    url: https://github.com/jax-ml/{{ name }}/archive/refs/tags/v{{ version }}.tar.gz
    sha256: 4247e493b5b6fa01574b14fb0377ba3a6e76c7bdc0ae309f08d7d7bcc5bbbd7d
    patches:
      - patches/0001-unvendor-eigen.patch

build:
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0
  skip: true  # [py<39]

requirements:
  build:
    - {{ stdlib('c') }}
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
  host:
    - python
    - pip
    - numpy {{ numpy }}
    - setuptools >=80.8.0,<81.0.0
    # third-party unvendor
    - eigen 5.0.1
  run:
    - python
    - numpy >=1.21.2  # [py==310]
    - numpy >=1.23.3  # [py==311]
    - numpy >=1.26.0  # [py==312]
    - numpy >=2.1.0  # [py==313]

test:
  source_files:
    - ml_dtypes/tests
  imports:
    - ml_dtypes
  requires:
    - pip
    - pytest
    - absl-py
  commands:
    - pip check
    - python -c "from importlib.metadata import version; assert(version('{{ name }}')=='{{ version }}')"
    - pytest -v ml_dtypes/tests

about:
  home: https://pypi.org/project/ml-dtypes
  summary: A stand-alone implementation of several NumPy dtype extensions used in machine learning libraries
  description: |
    ml_dtypes is a stand-alone implementation of several NumPy dtype extensions used in machine learning libraries, including:
    bfloat16: an alternative to the standard float16 format
    float8_*: several experimental 8-bit floating point representations including:
    float8_e4m3b11fnuz, float8_e4m3fn, float8_e4m3fnuz, float8_e5m2, float8_e5m2fnuz
    int4 and uint4: low precision integer types.
  dev_url: https://github.com/jax-ml/ml_dtypes
  doc_url: https://github.com/jax-ml/ml_dtypes
  license: Apache-2.0
  license_family: APACHE
  license_file: LICENSE

extra:
  recipe-maintainers:
    - ngam
